# Spark基本工作原理

## Spark基本工作原理

### 分布式

- 首先我们在本地上编写spark程序，然后必须在某台能够链接spark的机器上提交该spark程序
- 然后spark集群从hadoop：HDFS、Hive上面读取数据，分布在spark的节点上
- 对节点上的数据进行处理，处理后的数据，可能会移动到其他节点中

### 主要基于内存

- 数据都是存到各个节点的内存中
- 所有的计算操作都是针对多个节点上的数据，进行并行计算操作

### 迭代式计算

- Spark和MapReduce的最大的不同在于：迭代式计算模型
- MapReduce，分为两个阶段，map和reduce，两个阶段处理完了，就结束了，所以我们在一个job里能做的处理有限，只能在map和reduce里处理
- Spark计算模型，可以分为n个阶段，因为它是内存迭代式的，我们在处理完一个阶段以后，可以继续往下处理很多阶段，而不是两个阶段。

### 输出

- Hadoop的HDFS、Hive
- MySQL、Hbase、DB
- 直接把结果返回客户端（运行spark程序的机器和进程）

## RDD

### 什么是RDD

- RDD是Spark提供的核心抽象，全称为Resillient Distributed Dataset，即弹性分布式数据集。
- RDD在抽象上来说是一种元素集合，包含了数据。它是被分区的，分为多个分区，每个分区分布在集群中的不同节点上，从而让RDD中的数据可以被并行操作。（分布式数据集）
- RDD通常通过Hadoop上的文件，即HDFS文件或者Hive表，来进行创建；有时也可以通过应用程序中的集合来创建。
- RDD最重要的特性就是，提供了容错性，可以自动从节点失败中恢复过来。即如果某个节点上的RDD partition，因为节点故障，导致数据丢了，那么RDD会自动通过自己的数据来源重新计算该partition。这一切对使用者是透明的。
- RDD的数据默认情况下存放在内存中的，但是在内存资源不足时，Spark会自动将RDD数据写入磁盘。（弹性）

### 举个例子

- 一个spark集群，一个RDD，在逻辑上抽象代表了一个HDFS文件，但是，他实际上是被分区的，分为多个分区，多个分区散落在Spark集群中，不同的节点上，比如说，RDD有90万个数据，分为9个partition，9个分区。（分布式）
- RDD的每个partition，在spark节点上存储时，默认都是存放在内存上的，但是如果说内存放不下这么多数据，比如每个节点最多放5万数据，但是每个partition是10万数据，那么就会把partition中的部分数据写入磁盘上，继续保存。（弹性）
- 现在节点9出现了故障，导致partition9的数据丢失，那么此时Spark也不会直接挂掉，RDD有很强的容错性，当它发现自己的数据丢失了以后，会自动从自己来源的数据重新计算，重新获取自己这份数据，这一切对用户，都是完全透明的。

> 面对上述以切，对于用户，都是完全透明的，也就是说，不用管RDD的数据存储在哪里，内存环视磁盘，只要关注，自己是针对RDD进行计算，和处理等等操作。
>
> 所以说RDD这种自动进行内存和磁盘之间权衡和切换的机制，就是RDD的弹性特点。

## Spark核心编程原理

- 首先，定义初始RDD，就是说，你要定义第一个RDD是从哪里读取数据，HDFS、Linux本地文件、程序中的集合
- 然后定义对RDD的计算操作，这个在spark里称之为算子，map、reduce、flatmap、groupByKey，比mapreduce提供的map和reduce强大太多了
- 然后，其实就是循环往复的过程，第一个计算完了之后，数据可能就会到了新的一批节点上，也就是变成一个新的RDD，然后再次反复，针对新的RDD定义计算操作
- 最后，就是获得最终的数据，将数据保存起来。