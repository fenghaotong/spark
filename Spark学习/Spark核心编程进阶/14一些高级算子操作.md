# 一些高级算子示例



### mapPartitions

- 类似map，不同之处在于，map算子，一次就处理一个partition中的一条数据
- mapPartitions算子，一次处理一个partition中所有的数据

**学生成绩查询案例**

[Java版本示例](src/java/MapPartitions.java)

### mapPartitionsWithIndex

- 这个算子可以拿到每个partition的index

**开学分班案例**

[Java版本示例](src/java/MapPartitionsWithIndex.java)



### sample

- 可以使用指定的比例，比如说0.1或者0.9，从RDD中随机抽取10%或者90%的数据
- 从RDD中随机抽取数据的功能
- 推荐不要设置第三个参数，feed

**公司年会抽奖案例**

[Java版本示例](src/java/Sample.java)

###  union

- 将两个RDD的数据，合并为一个RDD

**公司部分合并案例**

[Java版本示例](src/java/Union.java)

### intersection

- 获取两个rdd中，相同的数据
- 有的公司内，有些人可能同时在做不同的项目，属于不同的项目组
- 所以要针对代表两个项目组同事的rdd，取出其交集

**公司跨多项目人员查询案例**

[Java版本示例](src/java/Intersection.java)

### distinct

- 对rdd中的数据进行去重
-  uv统计案例
-  uv：user view，每天每个用户可能对网站会点击多次
- 此时，需要对用户进行去重，然后统计出每天有多少个用户访问了网站
- 而不是所有用户访问了网站多少次（pv）

**网站uv统计案例**

[Java版本示例](src/java/Distinct.java)

### aggregateByKey

- aggregateByKey，分为三个参数
  - 第一个参数是，每个key的初始值
  - 第二个是个函数，Seq Function，如何进行shuffle map-side的本地聚合
  - 第三个是个函数，Combiner Function，如何进行shuffle reduce-side的全局聚合
-  reduceByKey认为是aggregateByKey的简化版
- aggregateByKey最重要的一点是，多提供了一个函数，Seq Function
- 就是说自己可以控制如何对每个partition中的数据进行先聚合，类似于mapreduce中的，map-side combine
- 然后才是对所有partition中的数据进行全局聚合

**单词计数案例**

[Java版本示例](src/java/AggregateByKey.java)

![](img\aggregateBtKey.png)

### cartesian

- cartesian，中文名，笛卡尔乘积
- 比如说两个RDD，分别有10条数据，用了cartesian算子以后
- 两个RDD的每一条数据都会和另外一个RDD的每一条数据执行一次join
- 最终组成了一个笛卡尔乘积

**服装搭配案例**

[Java版本示例](src/java/Cartesian.java)

### coalesce

- coalesce算子，功能是将RDD的partition缩减，减少
- 将一定量的数据，压缩到更少的partition中去

**建议的使用场景，配合filter算子使用**

- 使用filter算子过滤掉很多数据以后，比如30%的数据，出现了很多partition中的数据不均匀的情况
- 此时建议使用coalesce算子，压缩rdd的partition数量
- 从而让各个partition中的数据都更加的紧凑

**公司部门整合案例**

[Java版本示例](src/java/Coalesce.java)

### repartition

- repartition算子，用于任意将rdd的partition增多，或者减少
- 与coalesce不同之处在于，coalesce仅仅能将rdd的partition变少
- 但是repartition可以将rdd的partiton变多

**建议使用的场景**

- 一个很经典的场景，使用Spark SQL从hive中查询数据时
- park SQL会根据hive对应的hdfs文件的block数量还决定加载出来的数据rdd有多少个partition
- 这里的partition数量，是我们根本无法设置的
- 可能它自动设置的partition数量过于少了，导致我们后面的算子的运行特别慢
- 此时就可以在Spark SQL加载hive数据到rdd中以后
- 立即使用repartition算子，将rdd的partition数量变多

**公司新增部门案例**

[Java版本示例](src/java/Repartition.java)

### takeSampled

- 与sample不同之处，两点
  1. action操作，sample是transformation操作
  2. 不能指定抽取比例，只能是抽取几个

**公司年会抽奖案例**

[Java版本示例](src/java/TakeSampled.java)





