# 用户访问session分析-模块介绍

1. 对用户访问session进行分析
2. JDBC辅助类封装
3. 用户访问session聚合统计
4. 按时间比例随机抽取session
5. 获取点击、下单和支付次数排名前10的品类
6. 获取top10品类的点击次数最多的10个session
7. 复杂性能调优全套解决方案
8. 十亿级数据troubleshooting经验总结
9. 数据倾斜全套完美解决方案
10. 模块功能演示

**模块的目标：对用户访问session进行分析**

1. 可以根据使用者指定的某些条件，筛选出指定的一些用户（有特定年龄、职业、城市）；
2. 对这些用户在指定日期范围内发起的session，进行聚合统计，比如，统计出访问时长在0~3s的session占总session数量的比例；
3. 按时间比例，比如一天有24个小时，其中12:00~13:00的session数量占当天总session数量的50%，当天总session数量是10000个，那么当天总共要抽取1000个session，那么12:00~13:00的用户，就得抽取1000*50%=500。而且这500个需要随机抽取。
4. 获取点击量、下单量和支付量都排名10的商品种类
5. 获取top10的商品种类的点击数量排名前10的session
6. 开发完毕了以上功能之后，需要进行大量、复杂、高端、全套的性能调优（大部分性能调优点，都是本人在实际开发过程中积累的经验，基本都是全网唯一）
7. 十亿级数据量的troubleshooting（故障解决）的经验总结
8. 数据倾斜的完美解决方案（全网唯一，非常高端，因为数据倾斜往往是大数据处理程序的性能杀手，很多人在遇到的时候，往往没有思路）
9. 使用mock（模拟）的数据，对模块进行调试、运行和演示效果

**在实际企业项目中的使用架构：**

1. J2EE的平台（美观的前端页面），通过这个J2EE平台可以让使用者，提交各种各样的分析任务，其中就包括一个模块，就是用户访问session分析模块；可以指定各种各样的筛选条件，比如年龄范围、职业、城市等等。。
2. J2EE平台接收到了执行统计分析任务的请求之后，会调用底层的封装了spark-submit的shell脚本（Runtime、Process），shell脚本进而提交我们编写的Spark作业。
3. Spark作业获取使用者指定的筛选参数，然后运行复杂的作业逻辑，进行该模块的统计和分析。
4. Spark作业统计和分析的结果，会写入MySQL中，指定的表
5. 最后，J2EE平台，使用者可以通过前端页面（美观），以表格、图表的形式展示和查看MySQL中存储的该统计分析任务的结果数据。

**用户访问session介绍**

- 用户在电商网站上，通常会有很多的点击行为，首页通常都是进入首页；然后可能点击首页上的一些商品；点击首页上的一些品类；也可能随时在搜索框里面搜索关键词；还可能将一些商品加入购物车；对购物车中的多个商品下订单；最后对订单中的多个商品进行支付。
- 用户的每一次操作，其实可以理解为一个action，比如点击、搜索、下单、支付
- 用户session，指的就是，从用户第一次进入首页，session就开始了。然后在一定时间范围内，直到最后操作完（可能做了几十次、甚至上百次操作）。离开网站，关闭浏览器，或者长时间没有做操作；那么session就结束了。
- 以上用户在网站内的访问过程，就称之为一次session。简单理解，session就是某一天某一个时间段内，某个用户对网站从打开/进入，到做了大量操作，到最后关闭浏览器。的过程。就叫做session。
- session实际上就是一个电商网站中最基本的数据和大数据。那么大数据，面向C端，也就是customer，消费者，用户端的，分析，基本是最基本的就是面向用户访问行为/用户访问session。