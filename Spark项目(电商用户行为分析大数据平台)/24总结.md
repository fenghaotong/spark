# 总结

**大数据集群环境的搭建**

CentOS 6.4、hadoop-2.5.0-cdh5.3.6、hive-0.13.1-cdh5.3.6、zookeeper-3.4.5-cdh5.3.6、kafka_2.9.2-0.8.1、flume-ng-1.5.0-cdh5.3.6以及日志采集流程、Spark 1.5.1

**企业级大数据项目的架构搭建**

- Java、配置管理组件、JDBC辅助组件（内置数据库连接池）、Domain与DAO模型
- scala：只适合用于编写一些比较纯粹的一些数据处理程序（比如说一些复杂的数据etl）

**J2EE与Spark组成的交互式大数据分析平台架构**

- 清楚了j2ee与spark组成的大数据平台架构
- 做出来的东西，都是要放在j2ee与spark的架构中的（task、spark触发、spark结果如何被展示）

**企业级大数据项目的开发流程**

贯穿了整个项目，每个模块，基本上都是按照这个完整的流程来的

- 数据分析（来源数据的分析）
- 需求分析（基于上述数据，要实现什么样的需求和功能）
- 技术方案设计（基于来源数据与需求，以及你所掌握的spark技术，设计方案来实现需求功能）
- 数据库设计（技术方案设计完了以后，要配合着技术方案，设计数据库中表）
- 编码实现（基于上述所有的东西，使用你掌握的spark技术，来编码，实现功能）
- 功能测试（包括本地测试和生产环境测试，spark的client和cluster的说明）
- 性能调优（spark core、spark sql、spark streaming）
- troubleshooting（项目上线以后，要及时解决出现的线上故障与报错）
- 解决数据倾斜（后期维护过程中，可能会出现的严重的性能问题）



一套项目课程，全面涵盖了90%以上的Spark Core、Spark SQL和Spark Streaming，几乎所有的初中高级技术点；全面锻炼了学员的spark大数据项目实战能力；视频至少看一遍（最佳是两遍以上），代码至少两遍（一遍跟着视频敲，一遍脱开视频自己敲）；将大数据项目与spark技术融会贯通

**用户访问session分析模块**

- 用户session分析业务：复杂业务逻辑，session聚合统计、session随机抽取、top10热门品类、top10活跃用户
  1. 技术点：数据的过滤与聚合、自定义Accumulator、按时间比例随机抽取算法、二次排序、分组取topN
  2. 性能调优方案：普通调优、jvm调优、shuffle调优、算子调优
  3. troubleshooting经验
  4. 数据倾斜解决方案：7种方案

**页面单跳转化率模块**

**各区域热门商品统计模块**

1. 技术点：Hive与MySQL异构数据源、RDD转换为DataFrame、注册和使用临时表、自定义UDAF聚合函数、自定义get_json_object等普通函数、Spark SQL的高级内置函数（if与case when等）、开窗函数（高端）
2. Spark SQL数据倾斜解决方案

**广告点击流量实时统计模块**

- 技术点：动态黑名单机制（动态生成黑名单以及黑名单过滤）、transform、updateStateByKey、transform与Spark SQL整合、window滑动窗口、高性能写数据库
- HA方案：高可用性方案，3种
- 性能调优：常用的性能调优的技巧